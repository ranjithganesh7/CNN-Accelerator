# Real-Time Object Detection Using Hardware-Accelerated CNN on Xilinx Zynq FPGA with Arm Processor

## Overview
This project demonstrates real-time Convolutional Neural Network (CNN) inference acceleration on a Xilinx Zynq-7000 SoC. By heavily leveraging hardware/software co-design, compute-intensive layers of the CNN are offloaded to the FPGA programmable logic (PL), while the Arm Cortex-A9 processor (PS) handles system control, data movement, and image preprocessing.

Developed as part of the Bharat AI-SoC Student Challenge and ARM hackathon, this hardware-accelerated CNN IP was built using Vitis HLS, integrated via Vivado, and deployed on a PYNQ-Z2 board.

## Key Features
- FPGA-Accelerated Inference: Custom IP for spatial convolution and pooling.
- HW/SW Co-Design: Seamless partitioning using Vitis HLS and Vivado.
- Real-Time Processing: High-throughput object detection and image classification.
- Quantitative Benchmarking: Built-in scripts to compare latency, throughput, and power against a purely software-driven CPU baseline.

## System Stack
- Hardware: Xilinx Zynq-7000 SoC (PYNQ-Z2 Development Board)
- Software Design: Vitis HLS 2023.1, Vivado Design Suite 2023.1
- Embedded Environment: PYNQ Linux, Python 3.x, OpenCV

## Performance Highlights
| Metric | CPU Only | FPGA Accelerated |
|------|---------|-----------------|
| Latency (ms) | 3347.1 | 114.117 |
| FPS | 1.86 | 8.76 |
| Throughput | 0.056 | 0.108 |
| Power Efficiency | Baseline | Improved |

## GitHub Repository Structure
```
root/
â”œâ”€â”€ Detection/
â”‚   â”œâ”€â”€ hardware/
â”‚   â”‚   â”œâ”€â”€ hls/
â”‚   â”‚   â”‚   â””â”€â”€ dpu_core.cpp
â”‚   â”‚   â””â”€â”€ software/
â”‚   â”‚       â””â”€â”€ cpu_hw_inference.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ hardware/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ hls/
â”‚   â”‚   â”œâ”€â”€ dpu_core.cpp
â”‚   â”‚   â””â”€â”€ weights.h
â”‚   â””â”€â”€ vivado/
â”‚       â”œâ”€â”€ bitstream/
â”‚       â”‚   â”œâ”€â”€ design_1_wrapper.bit
â”‚       â”‚   â””â”€â”€ design_1_wrapper.hwh
â”‚       â”œâ”€â”€ hdl/
â”‚       â”‚   â””â”€â”€ design_1_wrapper.v
â”‚       â””â”€â”€ tcl/
â”‚           â”œâ”€â”€ design_1.bd
â”‚           â””â”€â”€ design_1.tcl
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ dataset.md
â”‚   â”œâ”€â”€ training.py
â”‚   â””â”€â”€ weights.h
â””â”€â”€ software/
    â”œâ”€â”€ README.md
    â”œâ”€â”€ cpu_inference.py
    â””â”€â”€ hw_inference.py
```

## Demo
â–¶ Demo Video: [https://drive.google.com/file/d/1zEg1VLj9V9LxN7ka2FiaaFTp8HAQc8l4/view?usp=drive_link](https://drive.google.com/file/d/1zEg1VLj9V9LxN7ka2FiaaFTp8HAQc8l4/view?usp=drive_link)


## ðŸš€ How to Run

### Prerequisites
- PYNQ-Z2 (or compatible Zynq board)
- SD Card (â‰¥16GB recommended)
- PYNQ Linux image
- Python 3.x
- OpenCV installed on board
- FPGA bitstream (`.bit`) and hardware handoff file (`.hwh`)
- CNN model weights

### Hardware Setup
1. Flash the PYNQ image to the SD card  
2. Insert the SD card into the board  
3. Connect power, Ethernet/USB, and camera (optional)  
4. Power ON the board  



## Authors
- Royce Niran George A
- Kamalesh S
- Ranjith Ganesh B

